[
  {
    "objectID": "2_linear_regression_tidymodels/doc.html",
    "href": "2_linear_regression_tidymodels/doc.html",
    "title": "Tidymodels Linear Regression",
    "section": "",
    "text": "We will demonstrate how to fit a linear regression model with the iris dataset.\nFirst we will load the data.\n\nlibrary(knitr)\nlibrary(tidyverse)\n\ndata(iris)\n\niris = iris |>\n  rename_with(~ tolower(gsub(\".\", \"_\", .x, fixed = TRUE)))\n\nNext, we will visualise the data."
  },
  {
    "objectID": "2_linear_regression_tidymodels/doc.html#regression",
    "href": "2_linear_regression_tidymodels/doc.html#regression",
    "title": "Tidymodels Linear Regression",
    "section": "Regression",
    "text": "Regression\nNext we will fit a linear regression model.\n\n\n\nCall:\nlm(formula = petal_width ~ petal_length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56515 -0.12358 -0.01898  0.13288  0.64272 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.363076   0.039762  -9.131  4.7e-16 ***\npetal_length  0.415755   0.009582  43.387  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2065 on 148 degrees of freedom\nMultiple R-squared:  0.9271,    Adjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: < 2.2e-16\n\n\nNext, we will view some diagnostics."
  },
  {
    "objectID": "2_linear_regression_tidymodels/doc.html#session-information",
    "href": "2_linear_regression_tidymodels/doc.html#session-information",
    "title": "Tidymodels Linear Regression",
    "section": "Session Information",
    "text": "Session Information\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.2   stringr_1.4.1   dplyr_1.0.10    purrr_0.3.5    \n [5] readr_2.1.3     tidyr_1.2.1     tibble_3.1.8    ggplot2_3.3.6  \n [9] tidyverse_1.3.2 knitr_1.40     \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0    xfun_0.34           haven_2.5.1        \n [4] gargle_1.2.1        colorspace_2.0-3    vctrs_0.5.0        \n [7] generics_0.1.3      htmltools_0.5.3     yaml_2.3.6         \n[10] utf8_1.2.2          rlang_1.0.6         pillar_1.8.1       \n[13] withr_2.5.0         glue_1.6.2          DBI_1.1.3          \n[16] dbplyr_2.2.1        modelr_0.1.9        readxl_1.4.1       \n[19] lifecycle_1.0.3     munsell_0.5.0       gtable_0.3.1       \n[22] cellranger_1.1.0    rvest_1.0.3         htmlwidgets_1.5.4  \n[25] evaluate_0.17       tzdb_0.3.0          fastmap_1.1.0      \n[28] fansi_1.0.3         broom_1.0.1         backports_1.4.1    \n[31] scales_1.2.1        googlesheets4_1.0.1 jsonlite_1.8.3     \n[34] fs_1.5.2            hms_1.1.2           digest_0.6.30      \n[37] stringi_1.7.8       grid_4.2.1          cli_3.4.1          \n[40] tools_4.2.1         magrittr_2.0.3      crayon_1.5.2       \n[43] pkgconfig_2.0.3     ellipsis_0.3.2      xml2_1.3.3         \n[46] reprex_2.0.2        googledrive_2.0.0   lubridate_1.8.0    \n[49] assertthat_0.2.1    rmarkdown_2.17      httr_1.4.4         \n[52] rstudioapi_0.14     R6_2.5.1            compiler_4.2.1"
  },
  {
    "objectID": "1_linear_regression/doc.html",
    "href": "1_linear_regression/doc.html",
    "title": "Linear Regression",
    "section": "",
    "text": "We will demonstrate how to fit a linear regression model to the iris dataset.\nFirst we will load the data.\n\nlibrary(knitr)\nlibrary(tidyverse)\n\ndata(iris)\n\niris = iris |>\n  rename_with(~ tolower(gsub(\".\", \"_\", .x, fixed = TRUE)))\n\niris |>\n  head()\n\n  sepal_length sepal_width petal_length petal_width species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nNext, we will visualise the data."
  },
  {
    "objectID": "1_linear_regression/doc.html#regression",
    "href": "1_linear_regression/doc.html#regression",
    "title": "Linear Regression",
    "section": "Regression",
    "text": "Regression\nNext we will fit a linear regression model.\n\n\n\nCall:\nlm(formula = petal_width ~ petal_length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56515 -0.12358 -0.01898  0.13288  0.64272 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.363076   0.039762  -9.131  4.7e-16 ***\npetal_length  0.415755   0.009582  43.387  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2065 on 148 degrees of freedom\nMultiple R-squared:  0.9271,    Adjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: < 2.2e-16\n\n\n\nDiagnostics\nNext, we will view some diagnostics."
  },
  {
    "objectID": "1_linear_regression/doc.html#session-information",
    "href": "1_linear_regression/doc.html#session-information",
    "title": "Linear Regression",
    "section": "Session Information",
    "text": "Session Information\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.2   stringr_1.4.1   dplyr_1.0.10    purrr_0.3.5    \n [5] readr_2.1.3     tidyr_1.2.1     tibble_3.1.8    ggplot2_3.3.6  \n [9] tidyverse_1.3.2 knitr_1.40     \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.2.0    xfun_0.34           haven_2.5.1        \n [4] gargle_1.2.1        colorspace_2.0-3    vctrs_0.5.0        \n [7] generics_0.1.3      htmltools_0.5.3     yaml_2.3.6         \n[10] utf8_1.2.2          rlang_1.0.6         pillar_1.8.1       \n[13] withr_2.5.0         glue_1.6.2          DBI_1.1.3          \n[16] dbplyr_2.2.1        modelr_0.1.9        readxl_1.4.1       \n[19] lifecycle_1.0.3     munsell_0.5.0       gtable_0.3.1       \n[22] cellranger_1.1.0    rvest_1.0.3         htmlwidgets_1.5.4  \n[25] evaluate_0.17       tzdb_0.3.0          fastmap_1.1.0      \n[28] fansi_1.0.3         broom_1.0.1         backports_1.4.1    \n[31] scales_1.2.1        googlesheets4_1.0.1 jsonlite_1.8.3     \n[34] fs_1.5.2            hms_1.1.2           digest_0.6.30      \n[37] stringi_1.7.8       grid_4.2.1          cli_3.4.1          \n[40] tools_4.2.1         magrittr_2.0.3      crayon_1.5.2       \n[43] pkgconfig_2.0.3     ellipsis_0.3.2      xml2_1.3.3         \n[46] reprex_2.0.2        googledrive_2.0.0   lubridate_1.8.0    \n[49] assertthat_0.2.1    rmarkdown_2.17      httr_1.4.4         \n[52] rstudioapi_0.14     R6_2.5.1            compiler_4.2.1"
  },
  {
    "objectID": "2_linear_regression_mlflow/doc.html",
    "href": "2_linear_regression_mlflow/doc.html",
    "title": "MLFlow Linear Regression",
    "section": "",
    "text": "We will demonstrate how to fit a linear regression model package to the Star Wars dataset.\nSubsequently, we will track the experiment and save the model to an MLFlow server. We use the carrier package to serialize the model (write an in-memory object to file).\n\n# Constants\n\nMLFLOW_URL = \"http://mlflow:5000\"\n\n# Imports\n\nlibrary(carrier)\nlibrary(DataExplorer)\nlibrary(knitr)\nlibrary(reticulate)\nuse_condaenv(\"r-mlflow-1.30.0\")\nlibrary(mlflow)\nmlflow::mlflow_set_tracking_uri(MLFLOW_URL)\nlibrary(tidyverse)\n\n# Load data\n\ndata = dplyr::starwars |>\n   mutate_if(is.numeric, ~ replace_na(.,0))\n\ndata |>\n  head()\n\n# A tibble: 6 × 14\n  name         height  mass hair_…¹ skin_…² eye_c…³ birth…⁴ sex   gender homew…⁵\n  <chr>         <int> <dbl> <chr>   <chr>   <chr>     <dbl> <chr> <chr>  <chr>  \n1 Luke Skywal…    172    77 blond   fair    blue       19   male  mascu… Tatooi…\n2 C-3PO           167    75 <NA>    gold    yellow    112   none  mascu… Tatooi…\n3 R2-D2            96    32 <NA>    white,… red        33   none  mascu… Naboo  \n4 Darth Vader     202   136 none    white   yellow     41.9 male  mascu… Tatooi…\n5 Leia Organa     150    49 brown   light   brown      19   fema… femin… Aldera…\n6 Owen Lars       178   120 brown,… light   blue       52   male  mascu… Tatooi…\n# … with 4 more variables: species <chr>, films <list>, vehicles <list>,\n#   starships <list>, and abbreviated variable names ¹​hair_color, ²​skin_color,\n#   ³​eye_color, ⁴​birth_year, ⁵​homeworld"
  },
  {
    "objectID": "2_linear_regression_mlflow/doc.html#regression",
    "href": "2_linear_regression_mlflow/doc.html#regression",
    "title": "MLFlow Linear Regression",
    "section": "Regression",
    "text": "Regression\nNext we will fit a linear regression model.\n\n\n\nCall:\nlm(formula = petal_width ~ petal_length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.56515 -0.12358 -0.01898  0.13288  0.64272 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  -0.363076   0.039762  -9.131  4.7e-16 ***\npetal_length  0.415755   0.009582  43.387  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2065 on 148 degrees of freedom\nMultiple R-squared:  0.9271,    Adjusted R-squared:  0.9266 \nF-statistic:  1882 on 1 and 148 DF,  p-value: < 2.2e-16\n\n\nNext, we will view some diagnostics."
  },
  {
    "objectID": "2_linear_regression_mlflow/doc.html#session-information",
    "href": "2_linear_regression_mlflow/doc.html#session-information",
    "title": "MLFlow Linear Regression",
    "section": "Session Information",
    "text": "Session Information\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.2      stringr_1.4.1      dplyr_1.0.10       purrr_0.3.5       \n [5] readr_2.1.3        tidyr_1.2.1        tibble_3.1.8       ggplot2_3.3.6     \n [9] tidyverse_1.3.2    mlflow_1.30.0      reticulate_1.26    knitr_1.40        \n[13] DataExplorer_0.8.2 carrier_0.1.0     \n\nloaded via a namespace (and not attached):\n [1] httr_1.4.4          jsonlite_1.8.3      modelr_0.1.9       \n [4] assertthat_0.2.1    askpass_1.1         googlesheets4_1.0.1\n [7] cellranger_1.1.0    yaml_2.3.6          pillar_1.8.1       \n[10] backports_1.4.1     lattice_0.20-45     glue_1.6.2         \n[13] digest_0.6.30       promises_1.2.0.1    rvest_1.0.3        \n[16] colorspace_2.0-3    htmltools_0.5.3     httpuv_1.6.6       \n[19] Matrix_1.4-1        pkgconfig_2.0.3     broom_1.0.1        \n[22] haven_2.5.1         scales_1.2.1        processx_3.8.0     \n[25] later_1.3.0         tzdb_0.3.0          openssl_2.0.4      \n[28] googledrive_2.0.0   generics_0.1.3      ellipsis_0.3.2     \n[31] swagger_3.33.1      withr_2.5.0         cli_3.4.1          \n[34] crayon_1.5.2        readxl_1.4.1        magrittr_2.0.3     \n[37] evaluate_0.17       ps_1.7.2            fs_1.5.2           \n[40] fansi_1.0.3         xml2_1.3.3          tools_4.2.1        \n[43] data.table_1.14.4   hms_1.1.2           gargle_1.2.1       \n[46] lifecycle_1.0.3     reprex_2.0.2        munsell_0.5.0      \n[49] networkD3_0.4       compiler_4.2.1      forge_0.2.0        \n[52] rlang_1.0.6         grid_4.2.1          rstudioapi_0.14    \n[55] rappdirs_0.3.3      htmlwidgets_1.5.4   igraph_1.3.5       \n[58] base64enc_0.1-3     rmarkdown_2.17      gtable_0.3.1       \n[61] DBI_1.1.3           R6_2.5.1            ini_0.3.1          \n[64] gridExtra_2.3       lubridate_1.8.0     fastmap_1.1.0      \n[67] utf8_1.2.2          zeallot_0.1.0       stringi_1.7.8      \n[70] parallel_4.2.1      Rcpp_1.0.9          vctrs_0.5.0        \n[73] png_0.1-7           dbplyr_2.2.1        tidyselect_1.2.0   \n[76] xfun_0.34"
  },
  {
    "objectID": "2_linear_regression_mlflow/doc.html#mlflow",
    "href": "2_linear_regression_mlflow/doc.html#mlflow",
    "title": "MLFlow Linear Regression",
    "section": "MLFlow",
    "text": "MLFlow\n\nRegistering Models\nWe will first create a new model in the model registry.\n\nclient = mlflow_client()\ntryCatch(\n  expr = {mlflow_delete_registered_model(\"sw_lm\", client = client)},\n  error = function(x) {}\n)\nmlflow_create_registered_model(\"sw_lm\", client = client, description = \"Perform predictions for Star Wars characters using linear regression.\")\n\n$name\n[1] \"sw_lm\"\n\n$creation_timestamp\n[1] 1.668548e+12\n\n$last_updated_timestamp\n[1] 1.668548e+12\n\n$description\n[1] \"Perform predictions for Star Wars characters using linear regression.\"\n\n\nWe will next execute an MLFlow run.\n\n\nMLFlow Run\n\ns3_bucket = \"s3://mlflow/sw_lm\"\n# Begin the run.\nexperiment = mlflow_set_experiment(experiment_name = \"sw_lm\", artifact_location = s3_bucket) \nrun = mlflow_start_run(client = client)\n\n# Save the model.\nsw_lm = lm(height ~ mass, data = data)\npackaged_sw_lm = carrier::crate(\n    function(x) {\n      stats::predict.lm(sw_lm, newdata = x)\n    },\n    sw_lm = sw_lm\n)\n\n# Log params and metrics.\nmlflow_log_param(\"Intercept\", sw_lm$coefficients[\"(Intercept)\"], client = client, run_id = run$run_uuid)\nmlflow_log_param(\"mass\", sw_lm$coefficients[\"mass\"], client = client, run_id = run$run_uuid)\nmlflow_log_metric(\"MSE\", mean(sw_lm$residuals^2), client = client, run_id = run$run_uuid)\n\n# Log predictions and actual values\nsw_lm |>\n  predict() |>\n  iwalk(\n    ~ mlflow_log_metric(\"prediction\", .x, step = as.numeric(.y), client = client, run_id = run$run_uuid)\n    )\n\ndata$height |> \n  iwalk(\n    ~ mlflow_log_metric(\"actual\",  .x, step = .y, client = client, run_id = run$run_uuid)\n    )\n\n# Save model to the registry.\ncrated_model = \"/tmp/sw_lm\"\nsaved_model = mlflow_save_model(packaged_sw_lm, crated_model)  \nlogged_model = mlflow_log_artifact(crated_model, client = client, run_id =  run$run_uuid) \n\n2022/11/15 21:36:42 INFO mlflow.store.artifact.cli: Logged artifact from local dir /tmp/sw_lm to artifact_path=None\n\nversioned_model = mlflow_create_model_version(\"sw_lm\", run$artifact_uri, run_id = run$run_uuid, client = client)\n\n# Generate report.\nsw_report = data |>\n  select_if(~ !is.list(.x)) |>\n  create_report(output_file = \"star_wars.html\", output_dir = \"/tmp\", report_title = \"Star Wars Report\", quiet = T)\nlogged_report = mlflow_log_artifact(\"/tmp/star_wars.html\", client = client, run_id =  run$run_uuid) \n\n2022/11/15 21:36:54 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars.html to artifact_path=None\n\n# Save plots.\nsw_plot = \"/tmp/star_wars_characters.png\"\npng(filename = sw_plot)\nplot(data$height, data$mass)\ndoff = dev.off()\nlogged_plot = mlflow_log_artifact(sw_plot, client = client, run_id =  run$run_uuid) \n\n2022/11/15 21:36:55 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars_characters.png to artifact_path=None\n\n# Save tibble.\ndata_csv = \"/tmp/star_wars_characters.csv\"\nwrite_csv(data, data_csv)\nlogged_csv = mlflow_log_artifact(data_csv, client = client, run_id =  run$run_uuid) \n\n2022/11/15 21:36:56 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars_characters.csv to artifact_path=None\n\n# End run.\nrun_end = mlflow_end_run(run_id =  run$run_uuid, client = client)\n\n\n\nLoading and Serving Models\nNext, we will load the model from the registry.\n\n# Remove the model from the R environment.\nprint(packaged_sw_lm)\n\n<crate> 39.87 kB\n* function: 26.64 kB\n* `sw_lm`: 13.19 kB\nfunction(x) stats::predict.lm(sw_lm)\n\nrm(packaged_sw_lm)\n\n# Load the model from the registry.\npackaged_sw_lm = mlflow_load_model(\"models:/sw_lm/1\")\nprint(packaged_sw_lm)\n\n<crate> 43.86 kB\n* function: 26.64 kB\n* `sw_lm`: 17.18 kB\nfunction(x) stats::predict.lm(sw_lm)\n\n\nFinally, we will demonstrate how to deploy the model using a model-as-a-service approach. Note that the mlflow::mlflow_rfunc_serve function can be used. Instead, we will launch the model using bash.\n\n\nexport MLFLOW_TRACKING_URI=http://mlflow:5000\n\n# ping http://0.0.0.0:9000/predict \nmlflow models serve -m \"models:/sw_lm/1\" -h 0.0.0.0 -p 9000 \n\nYou can also run the following command to deploy the model in a Docker container: docker compose restart rstudio_mlflow_serve_lm"
  },
  {
    "objectID": "2_linear_regression_mlflow/doc.html#minio",
    "href": "2_linear_regression_mlflow/doc.html#minio",
    "title": "MLFlow Linear Regression",
    "section": "Minio",
    "text": "Minio\nMinio is an object database that is used to store files within a centralised location.\nWe need to create a minio bucket. All of our files will be saved into this bucket.\n\n\nfrom minio import Minio\nimport json\nimport os\n\nminioClient = Minio(\n  os.environ['MLFLOW_S3_ENDPOINT_URL'].split('//')[1],\n  access_key=os.environ['AWS_ACCESS_KEY_ID'],\n  secret_key=os.environ['AWS_SECRET_ACCESS_KEY'],\n  secure = False\n)\n\nmlflow_names = [ bucket.name for bucket in minioClient.list_buckets() ]\nif 'mlflow' not in mlflow_names:\n  minioClient.make_bucket('mlflow')\n\nNext, we set the bucket policy.\n\n\npolicy = {\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:GetBucketLocation\",\n      \"Resource\":\"arn:aws:s3:::mlflow\"\n    },\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:ListBucket\",\n      \"Resource\":\"arn:aws:s3:::mlflow\"\n    },\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:GetObject\",\n      \"Resource\":\"arn:aws:s3:::mlflow/*\"\n    },\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:PutObject\",\n      \"Resource\":\"arn:aws:s3:::mlflow/*\"\n    }\n  ]}\n\nminioClient.set_bucket_policy('mlflow', json.dumps(policy))"
  },
  {
    "objectID": "3_tidy_linear_regression/doc.html",
    "href": "3_tidy_linear_regression/doc.html",
    "title": "Linear Regression with Tidymodels",
    "section": "",
    "text": "We will reuse the Star Wars dataset, and demonstrate how to use Tidymodels.\n\n# Constants\n\nMLFLOW_URL = \"http://mlflow:5000\"\n\n# Imports\n\nlibrary(carrier)\nlibrary(DataExplorer)\nlibrary(knitr)\nlibrary(reticulate)\nuse_condaenv(\"r-mlflow-1.30.0\")\nlibrary(mlflow)\nmlflow::mlflow_set_tracking_uri(MLFLOW_URL)\nlibrary(tidymodels)\nlibrary(tidyverse)\n\n# Load data\ndata = dplyr::starwars |>\n  select(c(height, mass)) |>\n   mutate_if(is.numeric, ~ replace_na(.,0))\n\ndata |>\n  head()\n\n# A tibble: 6 × 2\n  height  mass\n   <int> <dbl>\n1    172    77\n2    167    75\n3     96    32\n4    202   136\n5    150    49\n6    178   120\n\n\nWe will perform an 80-20 train-test split to evaluate the generalisability of our model.\n\ndata_split = initial_split(data, prop = 0.8)\ndata_train = training(data_split)\ndata_test = testing(data_split)"
  },
  {
    "objectID": "3_tidy_linear_regression/doc.html#mlflow",
    "href": "3_tidy_linear_regression/doc.html#mlflow",
    "title": "Linear Regression with Tidymodels",
    "section": "MLFlow",
    "text": "MLFlow\nWe will next demonstrate how to integrate Tidymodels with MLFlow.\n\nRegistering Models\nWe will first create a new model in the model registry.\n\nclient = mlflow_client()\ntryCatch(\n  expr = {mlflow_delete_registered_model(\"sw_rf\", client = client)},\n  error = function(x) {}\n)\nmlflow_create_registered_model(\"sw_rf\", client = client, description = \"Perform predictions for Star Wars characters using Random Forest.\")\n\n$name\n[1] \"sw_rf\"\n\n$creation_timestamp\n[1] 1.668548e+12\n\n$last_updated_timestamp\n[1] 1.668548e+12\n\n$description\n[1] \"Perform predictions for Star Wars characters using Random Forest.\"\n\n\nWe will next execute an MLFlow run.\n\n\nMLFlow Run\n\nMetric Tracking\nWe will log the metrics and parameters for the random forest run.\n\n# See https://mdneuzerling.com/post/tracking-tidymodels-with-mlflow/\n\nlog_workflow_parameters = function(workflow, client, run) {\n  spec = workflows::extract_spec_parsnip(workflow)\n  parameter_names = names(spec$args)\n  parameter_values = lapply(spec$args, rlang::get_expr)\n  for(i in seq_along(spec$args)) {\n    parameter_name = parameter_names[[i]]\n    parameter_value = parameter_values[[i]]\n    if (!is.null(parameter_value)) {\n      mlflow_log_param(parameter_name, parameter_value, client = client, run_id = run$run_uuid)\n    }\n  }\n  workflow\n}\n\nlog_metrics = function(metrics, estimator = \"standard\", client, run) {\n  metrics |> \n    filter(.estimator == estimator) |>\n    pmap(\n      function(.metric, .estimator, .estimate) {\n        mlflow_log_metric(.metric, .estimate, client = client, run_id = run$run_uuid)  \n      }\n    )\n  metrics\n}\n\nNext, we will initiate the tidymodels run with MLFlow integration.\n\ns3_bucket = \"s3://mlflow/sw_rf\"\n# Begin the run.\nexperiment = mlflow_set_experiment(experiment_name = \"sw_rf\", artifact_location = s3_bucket) \nrun = mlflow_start_run(client = client)\n\n# Save the model.\nsw_rf = sw_workflow |>\n    finalize_workflow(hyperparameters) |>\n    log_workflow_parameters(client = client, run = run) |> \n    fit(data_train)\n\npackaged_sw_rf = carrier::crate(\n  function(x) workflows:::predict.workflow(sw_rf, x),\n  sw_rf = sw_rf\n)\n\n# Log params and metrics.\nmetrics = sw_rf |>\n    predict(data_test) |>\n    metric_set(rmse, mae, rsq)(data_test$height, .pred) |> \n    log_metrics(client = client, run = run)\n\n# Log predictions and actual values\nsw_rf |>\n  predict(new_data = data_test) |>\n  (function(x) x$.pred)() |>\n  iwalk(\n    ~ mlflow_log_metric(\"prediction\", .x, step = as.numeric(.y), client = client, run_id = run$run_uuid)\n    )\n\ndata_test$height |> \n  iwalk(\n    ~ mlflow_log_metric(\"actual\",  .x, step = .y, client = client, run_id = run$run_uuid)\n    )\n\n# Save model to the registry.\ncrated_model = \"/tmp/sw_rf\"\nsaved_model = mlflow_save_model(packaged_sw_rf, crated_model)  \nlogged_model = mlflow_log_artifact(crated_model, client = client, run_id =  run$run_uuid) \n\n2022/11/17 09:31:44 INFO mlflow.store.artifact.cli: Logged artifact from local dir /tmp/sw_rf to artifact_path=None\n\nversioned_model = mlflow_create_model_version(\"sw_rf\", run$artifact_uri, run_id = run$run_uuid, client = client)\n\n# Generate report.\nsw_report = data |>\n  select_if(~ !is.list(.x)) |>\n  create_report(output_file = \"star_wars.html\", output_dir = \"/tmp\", report_title = \"Star Wars Report\", quiet = T)\nlogged_report = mlflow_log_artifact(\"/tmp/star_wars.html\", client = client, run_id =  run$run_uuid) \n\n2022/11/17 09:31:49 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars.html to artifact_path=None\n\n# Save plots.\nsw_plot = \"/tmp/star_wars_characters.png\"\npng(filename = sw_plot)\nplot(data$height, data$mass)\ndoff = dev.off()\nlogged_plot = mlflow_log_artifact(sw_plot, client = client, run_id =  run$run_uuid) \n\n2022/11/17 09:31:50 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars_characters.png to artifact_path=None\n\n# Save tibble.\ndata_csv = \"/tmp/star_wars_characters.csv\"\nwrite_csv(data, data_csv)\nlogged_csv = mlflow_log_artifact(data_csv, client = client, run_id =  run$run_uuid) \n\n2022/11/17 09:31:51 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars_characters.csv to artifact_path=None\n\n# End run.\nrun_end = mlflow_end_run(run_id =  run$run_uuid, client = client)"
  },
  {
    "objectID": "3_tidy_linear_regression/doc.html#session-information",
    "href": "3_tidy_linear_regression/doc.html#session-information",
    "title": "Linear Regression with Tidymodels",
    "section": "Session Information",
    "text": "Session Information\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] ranger_0.14.1      rmarkdown_2.17     data.table_1.14.4  forcats_0.5.2     \n [5] stringr_1.4.1      readr_2.1.3        tidyverse_1.3.2    yardstick_1.1.0   \n [9] workflowsets_1.0.0 workflows_1.1.0    tune_1.0.1         tidyr_1.2.1       \n[13] tibble_3.1.8       rsample_1.1.0      recipes_1.0.2      purrr_0.3.5       \n[17] parsnip_1.0.2      modeldata_1.0.1    infer_1.0.3        ggplot2_3.3.6     \n[21] dplyr_1.0.10       dials_1.0.0        scales_1.2.1       broom_1.0.1       \n[25] tidymodels_1.0.0   mlflow_1.30.0      reticulate_1.26    knitr_1.40        \n[29] DataExplorer_0.8.2 carrier_0.1.0     \n\nloaded via a namespace (and not attached):\n  [1] readxl_1.4.1        backports_1.4.1     plyr_1.8.7         \n  [4] igraph_1.3.5        splines_4.2.1       listenv_0.8.0      \n  [7] digest_0.6.30       foreach_1.5.2       htmltools_0.5.3    \n [10] fansi_1.0.3         magrittr_2.0.3      googlesheets4_1.0.1\n [13] tzdb_0.3.0          globals_0.16.1      modelr_0.1.9       \n [16] gower_1.0.0         vroom_1.6.0         askpass_1.1        \n [19] hardhat_1.2.0       colorspace_2.0-3    rvest_1.0.3        \n [22] rappdirs_0.3.3      haven_2.5.1         xfun_0.34          \n [25] crayon_1.5.2        jsonlite_1.8.3      zeallot_0.1.0      \n [28] survival_3.3-1      iterators_1.0.14    glue_1.6.2         \n [31] gtable_0.3.1        gargle_1.2.1        ipred_0.9-13       \n [34] future.apply_1.9.1  DBI_1.1.3           Rcpp_1.0.9         \n [37] bit_4.0.4           GPfit_1.0-8         lava_1.7.0         \n [40] prodlim_2019.11.13  htmlwidgets_1.5.4   httr_1.4.4         \n [43] ellipsis_0.3.2      pkgconfig_2.0.3     farver_2.1.1       \n [46] nnet_7.3-17         sass_0.4.2          dbplyr_2.2.1       \n [49] utf8_1.2.2          reshape2_1.4.4      tidyselect_1.2.0   \n [52] labeling_0.4.2      rlang_1.0.6         DiceDesign_1.9     \n [55] later_1.3.0         munsell_0.5.0       cellranger_1.1.0   \n [58] tools_4.2.1         cachem_1.0.6        cli_3.4.1          \n [61] generics_0.1.3      evaluate_0.17       fastmap_1.1.0      \n [64] yaml_2.3.6          bit64_4.0.5         processx_3.8.0     \n [67] fs_1.5.2            forge_0.2.0         future_1.28.0      \n [70] xml2_1.3.3          compiler_4.2.1      rstudioapi_0.14    \n [73] curl_4.3.3          png_0.1-7           reprex_2.0.2       \n [76] lhs_1.1.5           bslib_0.4.0         stringi_1.7.8      \n [79] highr_0.9           ps_1.7.2            lattice_0.20-45    \n [82] Matrix_1.4-1        vctrs_0.5.0         pillar_1.8.1       \n [85] lifecycle_1.0.3     networkD3_0.4       furrr_0.3.1        \n [88] jquerylib_0.1.4     ini_0.3.1           httpuv_1.6.6       \n [91] R6_2.5.1            promises_1.2.0.1    gridExtra_2.3      \n [94] parallelly_1.32.1   codetools_0.2-18    MASS_7.3-57        \n [97] assertthat_0.2.1    openssl_2.0.4       withr_2.5.0        \n[100] swagger_3.33.1      parallel_4.2.1      hms_1.1.2          \n[103] grid_4.2.1          rpart_4.1.16        timeDate_4021.106  \n[106] class_7.3-20        googledrive_2.0.0   lubridate_1.8.0    \n[109] base64enc_0.1-3"
  },
  {
    "objectID": "2_linear_regression_mlflow/doc.html#grafana",
    "href": "2_linear_regression_mlflow/doc.html#grafana",
    "title": "MLFlow Linear Regression",
    "section": "Grafana",
    "text": "Grafana\nNext, access the Grafana home page. This application will allow you to build your own dashboards.\nGo to Configuration -> Data sources -> Add data source.\n\n\n\nGrafana Configuration Page\n\n\nSelect PostgreSQL as the data source. Enter the following values into the web form.\n\nHost: postgres:5432\nDatabase: docker_r_mlops\nUser: user (Default)\nPassword: pass (Default)\nTLS/SSL Mode: Disable\n\n\n\n\nGrafana Data Source Web Form\n\n\nClick Save & test.\nNext, go to Create -> Dashboard -> Add a new panel. Create the following query.\n\nDatabase: metrics\nTime column: step\nSelect: Column:value\nWhere: Remove the Macro: $__unixEpochFilter\n\nClick Zoom to data. Your dashboard should look like the below. Click Apply to save the dashboard.\n\n\n\nGrafana Dashboard\n\n\nView the dashboard again. Click Table view.\n\n\n\nTable View\n\n\nCongratulations. Feel free to add new panels and experiment with the various plot types supported by Grafana."
  },
  {
    "objectID": "3_tidy_linear_regression/doc.html#minio",
    "href": "3_tidy_linear_regression/doc.html#minio",
    "title": "MLFlow Linear Regression",
    "section": "Minio",
    "text": "Minio\nMinio is an object datavase th\nWe need to create a minio bucket. All of our files will be saved into this bucket.\n\n\nfrom minio import Minio\nimport json\nimport os\n\nminioClient = Minio(\n  os.environ['MLFLOW_S3_ENDPOINT_URL'].split('//')[1],\n  access_key=os.environ['AWS_ACCESS_KEY_ID'],\n  secret_key=os.environ['AWS_SECRET_ACCESS_KEY'],\n  secure = False\n)\n\nmlflow_names = [ bucket.name for bucket in minioClient.list_buckets() ]\nif 'mlflow' not in mlflow_names:\n  minioClient.make_bucket('mlflow')\n\nNext, we set the bucket policy.\n\n\npolicy = {\n  \"Version\":\"2012-10-17\",\n  \"Statement\":[\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:GetBucketLocation\",\n      \"Resource\":\"arn:aws:s3:::mlflow\"\n    },\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:ListBucket\",\n      \"Resource\":\"arn:aws:s3:::mlflow\"\n    },\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:GetObject\",\n      \"Resource\":\"arn:aws:s3:::mlflow/*\"\n    },\n    {\n      \"Sid\":\"\",\n      \"Effect\":\"Allow\",\n      \"Principal\":{\"AWS\":\"*\"},\n      \"Action\":\"s3:PutObject\",\n      \"Resource\":\"arn:aws:s3:::mlflow/*\"\n    }\n  ]}\n\nminioClient.set_bucket_policy('mlflow', json.dumps(policy))"
  },
  {
    "objectID": "3_tidy_linear_regression/doc.html#tidymodels",
    "href": "3_tidy_linear_regression/doc.html#tidymodels",
    "title": "Linear Regression with Tidymodels",
    "section": "Tidymodels",
    "text": "Tidymodels\nTidymodels is an R framework for machine learning modelling inspired by the functional programming style adopted by the tidyverse. In contrast with the popular caret package, Tidymodels is an entire framework composed of a collection of packages. Conversely, caret is a single package containing many machine learning methods and tools.\n\nRecipes\nThe purpose of Tidymodels recipes to create reproducible data preprocessing pipelines. A recipe is composed of a sequence of data preprocessing steps.\n\nsw_recipe = recipe(data_train) |>\n  update_role(everything(), new_role = \"support\") |> \n  update_role(height, new_role = \"outcome\") |>\n  update_role(mass, new_role = \"predictor\") |>\n  step_impute_mean(mass) |>\n  step_normalize(all_numeric(), -all_outcomes())\n\n\n\nRandom Forest\nOne purpose of Tidymodels is to provide a layer of abstraction between different packages. For instance, there are several packages such as randomForest and ranger that implement the random forest algorithm. With Tidymodels, we can easily switch between these different implementations and specify whether we are performing regression or classification.\n\n\n\n\nsw_model = rand_forest(trees = tune()) |>\n  set_engine(\"ranger\") |>\n  set_mode(\"regression\")\n\n\n\nWorkflow\nNext, we define a Tidymodel workflow. This allows us to combine the above preprocessing steps with a random forest regressor. Also note that Tidymodels encourages a high degree of modularity. We can save complex preprocessing recipes, and easily switch between different models.\n\nsw_workflow = workflows::workflow() |>\n  add_recipe(sw_recipe) |>\n  add_model(sw_model)\n\n\n\nHyperparameter Tuning\nWe will tune the optimal number of decision trees to use within the random forest ensemble.\n\ntree_grid = seq(50, 200, by = 50)\nsw_grid = expand_grid(trees = tree_grid)\n\nsw_grid_results = sw_workflow |>\n  tune_grid(resamples = vfold_cv(data_train, v = 5), grid = sw_grid)\n\nhyperparameters = sw_grid_results |> \n  select_by_pct_loss(metric = \"rmse\", limit = 5, trees)\n\nautoplot(sw_grid_results, metric = \"rmse\")"
  },
  {
    "objectID": "4_tidymodels_targets/doc.html",
    "href": "4_tidymodels_targets/doc.html",
    "title": "Integrating Tidymodels and Targets",
    "section": "",
    "text": "We will reuse the Star Wars dataset yet again, and demonstrate how to integrate Tidymodels with targets. Targets allows users to create pipelines for general-purpose workflows.\n\n# Constants\n\nMLFLOW_URL = \"http://mlflow:5000\"\n\n# Imports\n\nlibrary(carrier)\nlibrary(DataExplorer)\nlibrary(knitr)\nlibrary(reticulate)\nuse_condaenv(\"r-mlflow-1.30.0\")\nlibrary(mlflow)\nmlflow::mlflow_set_tracking_uri(MLFLOW_URL)\nlibrary(targets)\nlibrary(tidymodels)\nlibrary(tidyverse)\n\n# Load data\n\nload_sw_data = function() {\n  dplyr::starwars |>\n    select(c(height, mass)) |>\n    mutate_if(is.numeric, ~ replace_na(.,0))\n}\n\ndata = load_sw_data() \ndata |>\n  head()\n\n# A tibble: 6 × 2\n  height  mass\n   <int> <dbl>\n1    172    77\n2    167    75\n3     96    32\n4    202   136\n5    150    49\n6    178   120\n\n\nWe will perform an 80-20 train-test split to evaluate the generalisability of our model.\n\ndata_split = initial_split(data, prop = 0.8)\ndata_train = training(data_split)\ndata_test = testing(data_split)"
  },
  {
    "objectID": "4_tidymodels_targets/doc.html#tidymodels",
    "href": "4_tidymodels_targets/doc.html#tidymodels",
    "title": "Integrating Tidymodels and Targets",
    "section": "Tidymodels",
    "text": "Tidymodels\nTidymodels is an R framework for machine learning modelling inspired by the functional programming style adopted by the tidyverse. In contrast with the popular caret package, Tidymodels is an entire framework composed of a collection of packages. Conversely, caret is a single package containing many machine learning methods and tools.\n\nRecipes\nThe purpose of Tidymodels recipes to create reproducible data preprocessing pipelines. A recipe is composed of a sequence of data preprocessing steps.\n\npreprocess_data_recipe = function(data_train) {\n  recipe(data_train) |>\n    update_role(everything(), new_role = \"support\") |> \n    update_role(height, new_role = \"outcome\") |>\n    update_role(mass, new_role = \"predictor\") |>\n    step_impute_mean(mass) |>\n    step_normalize(all_numeric(), -all_outcomes())\n}\n\nsw_recipe = preprocess_data_recipe(data_train)  \n\n\n\nRandom Forest\nOne purpose of Tidymodels is to provide a layer of abstraction between different packages. For instance, there are several packages such as randomForest and ranger that implement the random forest algorithm. With Tidymodels, we can easily switch between these different implementations and specify whether we are performing regression or classification.\n\n\n\n\nget_rf = function() {\n  rand_forest(trees = tune()) |>\n    set_engine(\"ranger\") |>\n    set_mode(\"regression\")\n}\nsw_model = get_rf()\n\n\n\nWorkflow\nNext, we define a Tidymodel workflow. This allows us to combine the above preprocessing steps with a random forest regressor. Also note that Tidymodels encourages a high degree of modularity. We can save complex preprocessing recipes, and easily switch between different models.\n\ndefine_workflow = function(sw_recipe, sw_model) {\n  workflows::workflow() |>\n    add_recipe(sw_recipe) |>\n    add_model(sw_model)\n}\nsw_workflow = define_workflow(sw_recipe, sw_model)\n\n\n\nHyperparameter Tuning\nWe will tune the optimal number of decision trees to use within the random forest ensemble.\n\ntree_grid = seq(50, 200, by = 50)\nsw_grid = expand_grid(trees = tree_grid)\n\nsw_grid_results = sw_workflow |>\n  tune_grid(resamples = vfold_cv(data_train, v = 5), grid = sw_grid)\n\nhyperparameters = sw_grid_results |> \n  select_by_pct_loss(metric = \"rmse\", limit = 5, trees)"
  },
  {
    "objectID": "4_tidymodels_targets/doc.html#mlflow",
    "href": "4_tidymodels_targets/doc.html#mlflow",
    "title": "Integrating Tidymodels and Targets",
    "section": "MLFlow",
    "text": "MLFlow\nWe will next demonstrate how to integrate Tidymodels with MLFlow.\n\nRegistering Models\nWe will first create a new model in the model registry.\n\nclient = mlflow_client()\ntryCatch(\n  expr = {mlflow_delete_registered_model(\"sw_rf\", client = client)},\n  error = function(x) {}\n)\nmlflow_create_registered_model(\"sw_rf\", client = client, description = \"Perform predictions for Star Wars characters using Random Forest.\")\n\n$name\n[1] \"sw_rf\"\n\n$creation_timestamp\n[1] 1.668677e+12\n\n$last_updated_timestamp\n[1] 1.668677e+12\n\n$description\n[1] \"Perform predictions for Star Wars characters using Random Forest.\"\n\n\nWe will next execute an MLFlow run.\n\n\nMLFlow Run\n\nMetric Tracking\nWe will log the metrics and parameters for the random forest run.\n\n# See https://mdneuzerling.com/post/tracking-tidymodels-with-mlflow/\n\nlog_workflow_parameters = function(workflow, client, run) {\n  spec = workflows::extract_spec_parsnip(workflow)\n  parameter_names = names(spec$args)\n  parameter_values = lapply(spec$args, rlang::get_expr)\n  for(i in seq_along(spec$args)) {\n    parameter_name = parameter_names[[i]]\n    parameter_value = parameter_values[[i]]\n    if (!is.null(parameter_value)) {\n      mlflow_log_param(parameter_name, parameter_value, client = client, run_id = run$run_uuid)\n    }\n  }\n  workflow\n}\n\nlog_metrics = function(metrics, estimator = \"standard\", client, run) {\n  metrics |> \n    filter(.estimator == estimator) |>\n    pmap(\n      function(.metric, .estimator, .estimate) {\n        mlflow_log_metric(.metric, .estimate, client = client, run_id = run$run_uuid)  \n      }\n    )\n  metrics\n}\n\nNext, we will initiate the tidymodels run with MLFlow integration.\n\ns3_bucket = \"s3://mlflow/sw_rf\"\n# Begin the run.\nexperiment = mlflow_set_experiment(experiment_name = \"sw_rf\", artifact_location = s3_bucket) \nrun = mlflow_start_run(client = client)\n\n# Save the model.\ntrain_rf = function(data_train, sw_workflow, hyperparameters, client, run) {\n  sw_workflow |>\n    finalize_workflow(hyperparameters) |>\n    log_workflow_parameters(client = client, run = run) |> \n    fit(data_train)\n}\nsw_rf = train_rf(data_train, sw_workflow, hyperparameters, client, run)\n\npackage_rf = function(sw_rf) {\n  carrier::crate(\n    function(x) workflows:::predict.workflow(sw_rf, x),\n    sw_rf = sw_rf\n  )\n}\npackaged_sw_rf = package_rf(sw_rf)\n\n# Log params and metrics.\nget_metrics = function(sw_rf, data_test, client, run) {\n  sw_rf |>\n    predict(data_test) |>\n    metric_set(rmse, mae, rsq)(data_test$height, .pred) |> \n    log_metrics(client = client, run = run)\n}\nmetrics = get_metrics(sw_rf, data_test, client, run)\n\n# Log predictions and actual values\nload_pred_actual = function(sw_rf, data_test, client, run) {\n  sw_rf |>\n    predict(new_data = data_test) |>\n    (function(x) x$.pred)() |>\n    iwalk(\n      ~ mlflow_log_metric(\"prediction\", .x, step = as.numeric(.y), \n                          client = client, run_id = run$run_uuid)\n      )\n  \n  data_test$height |> \n    iwalk(\n      ~ mlflow_log_metric(\"actual\",  .x, step = .y, \n                          client = client, run_id = run$run_uuid)\n      )\n}\nload_pred_actual(sw_rf, data_test, client, run)\n\n# Save model to the registry.\ncrated_model = \"/tmp/sw_rf\"\nsaved_model = mlflow_save_model(packaged_sw_rf, crated_model)  \nlogged_model = mlflow_log_artifact(crated_model, client = client, run_id =  run$run_uuid) \n\n2022/11/17 09:29:47 INFO mlflow.store.artifact.cli: Logged artifact from local dir /tmp/sw_rf to artifact_path=None\n\nversioned_model = mlflow_create_model_version(\"sw_rf\", run$artifact_uri, run_id = run$run_uuid, client = client)\n\n# Generate report.\ngenerate_sw_report = function(data, client, run) {\n data |>\n    select_if(~ !is.list(.x)) |>\n    create_report(output_file = \"star_wars.html\", output_dir = \"/tmp\", \n                  report_title = \"Star Wars Report\", quiet = T) \n  logged_report = mlflow_log_artifact(\"/tmp/star_wars.html\", \n                                      client = client, run_id =  run$run_uuid) \n}\nsw_report = generate_sw_report(data, client, run)\n\n2022/11/17 09:29:53 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars.html to artifact_path=None\n\n# Save plots.\nplot_sw = function(data, client, run) {\n  sw_plot = \"/tmp/star_wars_characters.png\"\n  png(filename = sw_plot)\n  plot(data$height, data$mass)\n  doff = dev.off()\n  logged_plot = mlflow_log_artifact(sw_plot, client = client, run_id =  run$run_uuid) \n}\nsw_plot = plot_sw(data, client, run)\n\n2022/11/17 09:29:55 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars_characters.png to artifact_path=None\n\n# Save tibble.\ndata_csv = \"/tmp/star_wars_characters.csv\"\nwrite_csv(data, data_csv)\nlogged_csv = mlflow_log_artifact(data_csv, client = client, run_id =  run$run_uuid) \n\n2022/11/17 09:29:56 INFO mlflow.store.artifact.cli: Logged artifact from local file /tmp/star_wars_characters.csv to artifact_path=None\n\n# End run.\nrun_end = mlflow_end_run(run_id =  run$run_uuid, client = client)\n\n\n\n\nLoading and Serving Models\nNext, we will load the random forest model from the registry.\n\n# Remove the model from the R environment.\nprint(packaged_sw_rf)\n\n<crate> 165.57 kB\n* function: 55.74 kB\n* `sw_rf`: 110.06 kB\nfunction(x) workflows:::predict.workflow(sw_rf, x)\n\nrm(packaged_sw_rf)\n\n# Load the model from the registry.\npackaged_sw_rf = mlflow_load_model(\"models:/sw_rf/1\")\nprint(packaged_sw_rf)\n\n<crate> 176.10 kB\n* function: 55.74 kB\n* `sw_rf`: 120.53 kB\nfunction(x) workflows:::predict.workflow(sw_rf, x)\n\n\nFinally, we will demonstrate how to deploy the model using a model-as-a-service approach. We will first demonstrate how to launch the model using bash.\n\n\nexport MLFLOW_TRACKING_URI=http://mlflow:5000\n\n# ping http://0.0.0.0:9000/predict \nmlflow models serve -m \"models:/sw_rf/1\" -h 0.0.0.0 -p 9000"
  },
  {
    "objectID": "4_tidymodels_targets/doc.html#targets",
    "href": "4_tidymodels_targets/doc.html#targets",
    "title": "Integrating Tidymodels and Targets",
    "section": "Targets",
    "text": "Targets\nWe will next replicate the above workflow using the targets package. Pipelines should be defined in a _targets.R file.\n\n# _targets.R\n\nlibrary(targets)\n\ntar_option_set(packages = c(\n  \"carrier\", \n  \"DataExplorer\",\n  \"knitr\",\n  \"mlflow\",\n  \"reticulate\",\n  \"tidyverse\", \n  \"tidymodels\"\n  )\n)\n\nlist(\n  tar_target(MLFLOW_URL, \"http://mlflow:5000\"),\n  tar_target(conda_active, use_condaenv(\"r-mlflow-1.30.0\")),\n  tar_target(mlflow_uri, mlflow::mlflow_set_tracking_uri(MLFLOW_URL)),\n  tar_target(data, load_sw_data()),\n  tar_target(data_split, initial_split(data, prop = 0.8)),\n  tar_target(data_train, training(data_split)),\n  tar_target(data_test, testing(data_split)),\n  tar_target(sw_recipe, preprocess_data_recipe(data_train)),\n  tar_target(sw_model, get_rf()),\n  tar_target(sw_workflow, define_workflow(sw_recipe, sw_model)),\n  tar_target(tree_grid, seq(50, 200, by = 50)),\n  tar_target(sw_grid, expand_grid(trees = tree_grid)),\n  tar_target(\n    sw_grid_results,\n    tune_grid(sw_workflow, resamples = vfold_cv(data_train, v = 5), grid = sw_grid)\n  ),\n  tar_target(\n    hyperparameters, \n    select_by_pct_loss(sw_grid_results, metric = \"rmse\", limit = 5, trees)\n  ),\n  tar_target(client, mlflow_client()),\n  tar_target(s3_bucket, \"s3://mlflow/sw_rf\"),\n  tar_target(experiment, mlflow_set_experiment(experiment_name = \"sw_rf\", artifact_location = s3_bucket)),\n  tar_target(experiment_id, mlflow_get_experiment(name = \"sw_rf\", client = client)$experiment_id),\n  tar_target(run, mlflow_start_run(client = client, experiment_id = experiment_id)),\n  tar_target(sw_rf, train_rf(data_train, sw_workflow, hyperparameters, client, run)),\n  tar_target(packaged_sw_rf, package_rf(sw_rf)),\n  tar_target(metrics, get_metrics(sw_rf, data_test, client, run)),\n  tar_target(pred_actual, load_pred_actual(sw_rf, data_test, client, run)),\n  tar_target(crated_model, \"/tmp/sw_rf\"),\n  tar_target(saved_model, mlflow_save_model(packaged_sw_rf, crated_model)),\n  tar_target(logged_model, mlflow_log_artifact(crated_model, client = client, \n                                               run_id =  run$run_uuid)),\n  tar_target(versioned_model, mlflow_create_model_version(\"sw_rf\", run$artifact_uri, \n                                                          run_id = run$run_uuid,\n                                                          client = client)),\n  tar_target(sw_report, generate_sw_report(data, client, run)),\n  tar_target(sw_plot, plot_sw(data, client, run)),\n  tar_target(data_csv, \"/tmp/star_wars_characters.csv\"),\n  tar_target(written_csv, write_csv(data, data_csv)),\n  tar_target(logged_csv, mlflow_log_artifact(data_csv, \n                                             client = client, run_id =  run$run_uuid)\n  ),\n  tar_target(run_end, mlflow_end_run(run_id =  run$run_uuid, client = client))\n)\n\nWe can visualise the workflow as a network next.\n\ntar_visnetwork()\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n✔ broom        1.0.1      ✔ recipes      1.0.2 \n✔ dials        1.0.0      ✔ rsample      1.1.0 \n✔ dplyr        1.0.10     ✔ tibble       3.1.8 \n✔ ggplot2      3.3.6      ✔ tidyr        1.2.1 \n✔ infer        1.0.3      ✔ tune         1.0.1 \n✔ modeldata    1.0.1      ✔ workflows    1.1.0 \n✔ parsnip      1.0.2      ✔ workflowsets 1.0.0 \n✔ purrr        0.3.5      ✔ yardstick    1.1.0 \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n✔ readr   2.1.3     ✔ forcats 0.5.2\n✔ stringr 1.4.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ readr::col_factor() masks scales::col_factor()\n✖ purrr::discard()    masks scales::discard()\n✖ dplyr::filter()     masks stats::filter()\n✖ stringr::fixed()    masks recipes::fixed()\n✖ dplyr::lag()        masks stats::lag()\n✖ readr::spec()       masks yardstick::spec()\n\n\n\n\n\n\nWe can execute the pipeline using the tar_make() function.\n\ntar_make()"
  },
  {
    "objectID": "4_tidymodels_targets/doc.html#session-information",
    "href": "4_tidymodels_targets/doc.html#session-information",
    "title": "Integrating Tidymodels and Targets",
    "section": "Session Information",
    "text": "Session Information\n\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-pc-linux-gnu (64-bit)\nRunning under: Ubuntu 20.04.5 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.9.0\nLAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.9.0\n\nlocale:\n [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              \n [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    \n [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   \n [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 \n [9] LC_ADDRESS=C               LC_TELEPHONE=C            \n[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.2      stringr_1.4.1      readr_2.1.3        tidyverse_1.3.2   \n [5] yardstick_1.1.0    workflowsets_1.0.0 workflows_1.1.0    tune_1.0.1        \n [9] tidyr_1.2.1        tibble_3.1.8       rsample_1.1.0      recipes_1.0.2     \n[13] purrr_0.3.5        parsnip_1.0.2      modeldata_1.0.1    infer_1.0.3       \n[17] ggplot2_3.3.6      dplyr_1.0.10       dials_1.0.0        scales_1.2.1      \n[21] broom_1.0.1        tidymodels_1.0.0   targets_0.13.5     mlflow_1.30.0     \n[25] reticulate_1.26    knitr_1.40         DataExplorer_0.8.2 carrier_0.1.0     \n\nloaded via a namespace (and not attached):\n  [1] googledrive_2.0.0   colorspace_2.0-3    ellipsis_0.3.2     \n  [4] class_7.3-20        fs_1.5.2            base64enc_0.1-3    \n  [7] rstudioapi_0.14     listenv_0.8.0       furrr_0.3.1        \n [10] prodlim_2019.11.13  fansi_1.0.3         lubridate_1.8.0    \n [13] xml2_1.3.3          codetools_0.2-18    splines_4.2.1      \n [16] zeallot_0.1.0       jsonlite_1.8.3      dbplyr_2.2.1       \n [19] png_0.1-7           compiler_4.2.1      httr_1.4.4         \n [22] backports_1.4.1     assertthat_0.2.1    Matrix_1.4-1       \n [25] fastmap_1.1.0       gargle_1.2.1        cli_3.4.1          \n [28] later_1.3.0         htmltools_0.5.3     tools_4.2.1        \n [31] igraph_1.3.5        gtable_0.3.1        glue_1.6.2         \n [34] rappdirs_0.3.3      Rcpp_1.0.9          cellranger_1.1.0   \n [37] DiceDesign_1.9      vctrs_0.5.0         iterators_1.0.14   \n [40] timeDate_4021.106   gower_1.0.0         xfun_0.34          \n [43] globals_0.16.1      networkD3_0.4       ps_1.7.2           \n [46] rvest_1.0.3         lifecycle_1.0.3     googlesheets4_1.0.1\n [49] future_1.28.0       MASS_7.3-57         ipred_0.9-13       \n [52] hms_1.1.2           promises_1.2.0.1    parallel_4.2.1     \n [55] swagger_3.33.1      yaml_2.3.6          forge_0.2.0        \n [58] gridExtra_2.3       rpart_4.1.16        stringi_1.7.8      \n [61] foreach_1.5.2       lhs_1.1.5           hardhat_1.2.0      \n [64] lava_1.7.0          rlang_1.0.6         pkgconfig_2.0.3    \n [67] evaluate_0.17       lattice_0.20-45     htmlwidgets_1.5.4  \n [70] processx_3.8.0      tidyselect_1.2.0    parallelly_1.32.1  \n [73] magrittr_2.0.3      R6_2.5.1            generics_0.1.3     \n [76] base64url_1.4       ini_0.3.1           DBI_1.1.3          \n [79] haven_2.5.1         pillar_1.8.1        withr_2.5.0        \n [82] survival_3.3-1      nnet_7.3-17         future.apply_1.9.1 \n [85] crayon_1.5.2        modelr_0.1.9        utf8_1.2.2         \n [88] tzdb_0.3.0          rmarkdown_2.17      readxl_1.4.1       \n [91] grid_4.2.1          data.table_1.14.4   callr_3.7.2        \n [94] reprex_2.0.2        digest_0.6.30       httpuv_1.6.6       \n [97] openssl_2.0.4       munsell_0.5.0       GPfit_1.0-8        \n[100] askpass_1.1"
  }
]