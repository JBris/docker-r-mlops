---
title: "MLFlow Linear Regression"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
---

## Star Wars Dataset

We will demonstrate how to fit a linear regression model package to the Star Wars dataset.

Subsequently, we will track the experiment and save the model to an MLFlow server. We use the *carrier* package to serialize the model (write an in-memory object to file).

```{r setup, include = TRUE, echo = TRUE, message = FALSE, warning = TRUE, cache = FALSE}

# Constants

MLFLOW_URL = "http://mlflow:5000"

# Imports

library(carrier)
library(DataExplorer)
library(knitr)
library(reticulate)
use_condaenv("r-mlflow-1.30.0")
library(mlflow)
mlflow::mlflow_set_tracking_uri(MLFLOW_URL)
library(tidyverse)

# Load data

data = dplyr::starwars |>
   mutate_if(is.numeric, ~ replace_na(.,0))

data |>
  head()
```

## Minio

Minio is an object datavase th

We need to create a minio bucket. All of our files will be saved into this bucket.

```{python minio-bucket, include = TRUE, echo = TRUE, message = FALSE, warning = TRUE, cache = TRUE}

from minio import Minio
import json
import os

minioClient = Minio(
  os.environ['MLFLOW_S3_ENDPOINT_URL'].split('//')[1],
  access_key=os.environ['AWS_ACCESS_KEY_ID'],
  secret_key=os.environ['AWS_SECRET_ACCESS_KEY'],
  secure = False
)

mlflow_names = [ bucket.name for bucket in minioClient.list_buckets() ]
if 'mlflow' not in mlflow_names:
  minioClient.make_bucket('mlflow')
```

Next, we set the bucket policy.

```{python minio-policy, include = TRUE, echo = TRUE, message = FALSE, warning = TRUE, cache = TRUE}

policy = {
  "Version":"2012-10-17",
  "Statement":[
    {
      "Sid":"",
      "Effect":"Allow",
      "Principal":{"AWS":"*"},
      "Action":"s3:GetBucketLocation",
      "Resource":"arn:aws:s3:::mlflow"
    },
    {
      "Sid":"",
      "Effect":"Allow",
      "Principal":{"AWS":"*"},
      "Action":"s3:ListBucket",
      "Resource":"arn:aws:s3:::mlflow"
    },
    {
      "Sid":"",
      "Effect":"Allow",
      "Principal":{"AWS":"*"},
      "Action":"s3:GetObject",
      "Resource":"arn:aws:s3:::mlflow/*"
    },
    {
      "Sid":"",
      "Effect":"Allow",
      "Principal":{"AWS":"*"},
      "Action":"s3:PutObject",
      "Resource":"arn:aws:s3:::mlflow/*"
    }
  ]}

minioClient.set_bucket_policy('mlflow', json.dumps(policy))
```

## MLFlow

### Registering Models

We will first create a new model in the model registry.

```{r mlflow-register, include = TRUE, echo = TRUE, message = FALSE, warning = TRUE, cache = TRUE}

client = mlflow_client()
tryCatch(
  expr = {mlflow_delete_registered_model("sw_lm", client = client)},
  error = function(x) {}
)
mlflow_create_registered_model("sw_lm", client = client, description = "Perform predictions for Star Wars characters using linear regression.")
```

We will next execute an MLFlow run.

### MLFlow Run

```{r mlflow-run, include = TRUE, echo = TRUE, message = FALSE, warning = TRUE, cache = TRUE}

s3_bucket = "s3://mlflow/sw_lm"
# Begin the run.
experiment = mlflow_set_experiment(experiment_name = "sw_lm", artifact_location = s3_bucket) 
run = mlflow_start_run(client = client)

# Save the model.
sw_lm = lm(height ~ mass, data = data)
packaged_sw_lm = carrier::crate(
    function(x) {
      stats::predict.lm(sw_lm, newdata = x)
    },
    sw_lm = sw_lm
)

# Log params and metrics.
mlflow_log_param("Intercept", sw_lm$coefficients["(Intercept)"], client = client, run_id = run$run_uuid)
mlflow_log_param("mass", sw_lm$coefficients["mass"], client = client, run_id = run$run_uuid)
mlflow_log_metric("MSE", mean(sw_lm$residuals^2), client = client, run_id = run$run_uuid)

# Log predictions and actual values
sw_lm |>
  predict() |>
  iwalk(
    ~ mlflow_log_metric("prediction", .x, step = as.numeric(.y), client = client, run_id = run$run_uuid)
    )

data$height |> 
  iwalk(
    ~ mlflow_log_metric("actual",  .x, step = .y, client = client, run_id = run$run_uuid)
    )

# Save model to the registry.
crated_model = "/tmp/sw_lm"
saved_model = mlflow_save_model(packaged_sw_lm, crated_model)  
logged_model = mlflow_log_artifact(crated_model, client = client, run_id =  run$run_uuid) 

versioned_model = mlflow_create_model_version("sw_lm", run$artifact_uri, run_id = run$run_uuid, client = client)

# Generate report.
sw_report = data |>
  select_if(~ !is.list(.x)) |>
  create_report(output_file = "star_wars.html", output_dir = "/tmp", report_title = "Star Wars Report", quiet = T)
logged_report = mlflow_log_artifact("/tmp/star_wars.html", client = client, run_id =  run$run_uuid) 

# Save plots.
sw_plot = "/tmp/star_wars_characters.png"
png(filename = sw_plot)
plot(data$height, data$mass)
doff = dev.off()
logged_plot = mlflow_log_artifact(sw_plot, client = client, run_id =  run$run_uuid) 

# Save tibble.
data_csv = "/tmp/star_wars_characters.csv"
write_csv(data, data_csv)
logged_csv = mlflow_log_artifact(data_csv, client = client, run_id =  run$run_uuid) 

# End run.
run_end = mlflow_end_run(run_id =  run$run_uuid, client = client)
```

### Loading and Serving Models

Next, we will load the model from the registry.

```{r mlflow-load, include = TRUE, echo = TRUE, message = FALSE, warning = TRUE, cache = TRUE}

# Remove the model from the R environment.
print(packaged_sw_lm)
rm(packaged_sw_lm)

# Load the model from the registry.
packaged_sw_lm = mlflow_load_model("models:/sw_lm/1")
print(packaged_sw_lm)
```

Finally, we will demonstrate how to deploy the model using a model-as-a-service approach. Note that the *mlflow::mlflow_rfunc_serve* function can be used. Instead, we will launch the model using bash.

```{bash mlflow-serve, include = TRUE, echo = TRUE, message = FALSE, warning = TRUE, cache = TRUE, eval = FALSE}

export MLFLOW_TRACKING_URI=http://mlflow:5000

# ping http://0.0.0.0:9000/predict 
mlflow models serve -m "models:/sw_lm/1" -h 0.0.0.0 -p 9000 
```

You can also run the following command to deploy the model in a Docker container: *docker compose restart rstudio_mlflow_serve_lm*

## Grafana

Next, access the Grafana home page. This application will allow you to build your own dashboards.

*Go to Configuration -\> Data sources -\> Add data source.*

![Grafana Configuration Page](images/1_configuration.png){width="624"}

*Select PostgreSQL as the data source. Enter the following values into the web form.*

-   Host: postgres:5432

-   Database: docker_r\_mlops

-   User: user (Default)

-   Password: pass (Default)

-   TLS/SSL Mode: Disable

![Grafana Data Source Web Form](images/2_grafana_web_form.png){width="614"}

*Click Save & test.*

*Next, go to Create -\> Dashboard -\> Add a new panel. Create the following query.*

-   Database: metrics

-   Time column: step

-   Select: Column:value

-   Where: Remove the Macro: \$\_\_unixEpochFilter

*Click Zoom to data. Your dashboard should look like the below. Click Apply to save the dashboard.*

![Grafana Dashboard](images/3_grafana_dashboard.png){width="607"}

*View the dashboard again. Click Table view.*

![Table View](images/4_table_view.png){width="608"}

*Congratulations. Feel free to add new panels and experiment with the various plot types supported by Grafana.*

## Session Information

```{r session-info, include = TRUE, echo = FALSE, message = FALSE, warning = TRUE, cache = FALSE}

sessionInfo()
```
